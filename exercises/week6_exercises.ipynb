{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DO NOT EDIT IF INSIDE annadl_f19 folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Transfer learning and multitask learning\n",
    "\n",
    "Deep neural networks are **extremely expensive** to train. Training a good classifier on a complex task, like telling objects in images apart, or determining whether a move in a board game is good, can take weeks on multiple GPUs, cost millions of dollars in cloud computing fees and release massive amounts of CO$_2$ into the atmosphere ([some more than 5 cars over their entire lifetimes!](https://arxiv.org/pdf/1906.02243.pdf)). Because of this, we want to be able to **reuse** weights in models we have trained. This is called transfer learning. The fundamental idea is that things learned in one context can be *transferred* to another context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exrcises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow [a very nice blog post](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/) written by Jason Brownlee of 'Machine Learning \n",
    "Mastery' for most of these exercises. In his blog post, Jason takes the reader through\n",
    "the process of using pretrained models in Keras. Below I have outlined the steps you\n",
    "will go through with reference to his blog post. I strongly recommend you read from the\n",
    "top and down to 'Models for Transfer Learning' before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first practical thing we need to figure out when doing transfer learning is loading pretrained models. Keras makes this very easy by offering a number of pretrained models for image classification which can be downloaded through their [Applications API](https://keras.io/applications/#densenet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications API arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading pretrained models, we will want to provide some arguments that depend on what\n",
    "we want to do with the model after loading. Below I ask you to explain, in your own words,\n",
    "what some of these parameters do. See the Application API reference on some of the models\n",
    "and the 'Models for Transfer Learning' section in Jason's bloc post for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.1**: In your own words, explain what the following function arguments do in\n",
    "the different model loading functions:\n",
    "1. `include_top`\n",
    "1. `weights`\n",
    "1. `input_shape`\n",
    "1. `pooling`\n",
    "1. `classes`\n",
    "1. Explain what 'global pooling' does, and why it is needed when `include_top=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a model and predict an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.2**: Following Jason's example under 'Pre-Trained Model as Classifier'\n",
    "classify [this image](https://66.media.tumblr.com/tumblr_mc46e7Zm4R1qbqngeo1_1280.jpg).\n",
    "Print not just the most likely label, but everything that `decode_predictions` returns.\n",
    ">\n",
    "> ***Important***: *Don't use VGG as he does. It's 500 MB to download, and will take too long.\n",
    "> Use one of the smaller models instead ([here](https://keras.io/applications/#documentation-for-individual-models)'s an overview of model sizes), such as DenseNet121.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple feature extractor for ML prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing the last layer, we can turn a pretrained convolutional neural network into a\n",
    "feature extractor. We can then use it to extract features of a large number of images and\n",
    "classify those using any machine learning model. Jason describes this under 'Pre-Trained Model as Feature Extractor Preprocessor'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.1:** Extract features for every datapoint in the [fashion-mnist dataset](https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles), and build a feature matrix X. Train an SVM classifier on the learned features, and report the accuracy on the test data.\n",
    ">\n",
    "> *Hint: You can import SVM from sklearn. It has a simply API, just check out some of the examples on the [documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the prediction task (switching out the last layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve roughly the same thing is to remove the last layer and insert a new one with a different number of outputs. Jason describes this under 'Pre-Trained Model as Feature Extractor in Model'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.2**: Do the same as above, but by following Jason's example under 'Pre-Trained Model as Feature Extractor in Mode'.\n",
    "Compare to the accuracy you got in 6.2.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
